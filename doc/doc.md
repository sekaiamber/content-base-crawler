# 基于DOM结构相似性的一类爬虫实现

## 0.概述

新年新气象，咱也有惊无险再就业成功，最近自己开始研究一些歪门邪道，想来最近部门对抗战场的同学们十分活跃，突然想实现一下自己之前的想法。（其实这个小程序十分简单，只实现了基本原理，而且最近1月新番十分良心，故花了不少时间在补番上）

废话少说，实际上是这样的。现在许多网站真的是机关算尽，对抗战场处处都是勾心斗角，变个`class`之类的小手段不说了，3天一改版，5天一大改版，让做爬取规则的小伙伴操碎了心。

大致上市面上这么几类爬虫产品：

* 传统的传统，规则爬取，根据DOM精确定位，抓取内容
* 标记爬取，大概就是傻瓜式的打开一个页面，点点这儿要爬，然后就自己去爬
* 新秀，根据一些**现阶段**不太靠谱的方式来爬取，像什么机器视觉之类的

我是一贯秉持**新的总是好的**的思想的，上述第三种方式即使现在看起来像是天方夜谭，但是随着技术发展，它们总会替代老的方法，毕竟连围棋都被AI攻陷了。

上面第一种方式，爬取的准确性和目的性十分高，但是制定规则十分依赖专业水平，并且无法抵抗DOM结构变动，不够傻瓜。第二种方式够傻瓜了，市面上类似八爪之类的软件就是这样，但是手动标记十分费时费力，并且也无法抵抗DOM结构变动。这两种方法在目标网站改版之后均需要重新处理规则，不符合程序员一贯的为了解决1分钟的事情花1小时去写个自动化程序的思路。

作为一个轮子爱好者，也是一个尽职尽责的前端工程师，深知网站开发的很多套路，所以总结出一套自以为十分屌的思路，就是下面要介绍的这种页面分析实现，它对DOM结构变动有十分强大的抵抗性，几乎堪称无敌，**但是她只适用于一部分页面的分析爬取，并且无法抵抗某些防守措施**，这部分将在3.4中说明，下面我会详细介绍一下这个分析方案的实现。

请诸位回想一下咱们最常上的网站中，许多页面都有**列表**存在，比如我经常上的[煎蛋](http://jandan.net)这类新闻类网站，也有类似[B站](http://www.bilibili.com/video/bangumi-two-1.html)这样的视频网站，也有像[本厂](https://s.taobao.com/search?q=%E8%B5%A4%E5%BA%A7%E7%81%AF%E9%87%8C&imgfile=&commend=all&ssid=s5-e&search_type=item&sourceId=tb.index&spm=a21bo.50862.201856-taobao-item.1&ie=utf8&initiative_id=tbindexz_20170108)这样的购物网站，这类网站高价值的内容存在下列特征：

1. 一个页面存在多条重复结构的内容，一般少则七八条，多则几十条，这些内容价值十分高，是我们的目标。
2. 根据现有前端开发技术和动态网页生成的机制，我们知道这些重复内容一般拥有同一个父节点。
3. 这些内容每一块一般对应同一个DOM结构，不会说同一块内容分散在不同的DOM中，这种具有价值的DOM一般具有一定的深度和复杂度。

基于上述特征，我们很容易想到，我们能否通过寻找这类重复DOM结构，来确定这部分内容，从而摆脱规则的束缚，而从DOM模式来入手，理论上只要页面表达的内容不变，不管页面结构如何变化，这类分析始终有效。

## 1. 一些前提和整体流程

很久很久以前，大概在AngularJS还未出现之前，当时后端模板当道，我们可以通过`curl`之类的工具直接获得网页HTML大部分内容（当时虽然也有JS插件这一说，DOM结构会在`DOMready`之后变化，但是有效的信息大部分是写在HTML代码中的，变动也只是在这些基础的HTML上动动手脚）。时过境迁，现在的前端技术比当年不知道高到哪里去了，出来了各种前端模板引擎，像`AngularJS`、`Vue`或者像`React`之类的妖孽，直接`curl`根本取不到想要的内容，故我们需要一个完整的浏览器实现来运行这些JS代码，才能获取需要的真实HTML代码。

市面上用于JS测试的浏览器实现有很多：

* PhantomJS，自己包装的一个黑盒浏览器，能跑JS能各种跳转，就是一个真实的浏览器环境
* 各类WebDriver，比如Chrome浏览器提供的[Chrome Driver](https://sites.google.com/a/chromium.org/chromedriver/downloads)，能使外部程序接入浏览器中，直接操作浏览器。
* JSDom，咱最喜欢的JS测试工具，纯JS实现的**模拟浏览器**，美中不足的是毕竟不是真实浏览器，很多行为跟真实有偏差。

本人也算是前端老司机了，纵然没爬过秋名山，也颇为熟悉西方那一套，还未开始写代码，都想好了各种开发选型的利弊，本例中为图方便使用`Python`开发，若是需要产品化，**强烈建议使用JS开发**。

本例中对页面内容的分析整体流程大概如下：

1. 使用给定的方式（WebDriver）来访问目标URL。
2. 等待页面加载，到特定时刻（一般是DomReady，也可以自己编程等待）开始加载分析。
3. 根据给定参数获取页面中结构相似的DOM集合的集合。
4. 返回集合供后续使用。

## 2. DOM的相似性比较

寻找结构相似的DOM，这个目标十分明确，听起来十分简单，事实上需要考虑很多东西。DOM结构存在严格的顺序和父子关系，这和一般模式识别中的信号量有十分大的不同，更接近文本分析的范畴。

### 2.1 DOM结构特征提取

我原本的思路是将HTML代码转化为信号，从`<body>`到`</body>`为时间，DOM节点上各个属性组合成为信号量，通过某些模式识别方式来获得重复模式，后来询问了一下专职这种问题的老婆大人，无果。仔细想想，我很难将父子关系描述到信号量里面，而且去除噪音也十分苦手，并且计算量是个不能逾越的大问题。

所以我接下来的思路是想将每个DOM节点转化为一个签名，一般的签名使用hash或者md5，微小的变动可能会导致签名的巨大改变，这在本例中是无法接受的。正好相反，我们需要的是完全相同的DOM生成同样的签名，而区别不大的DOM生成相似的签名。最终我约定了下列签名规则：

1. 签名不等长，这点十分重要，普通的签名为了存储和计算方便，均使用等长签名，而我们的签名需要表现DOM结构的规模并计算改变比例，越长的签名表示DOM越庞大，相对如果改变一位，那么改变的比例就相对较小。
2. 签名可逆，普通的签名实际上是对内容进行了压缩，而本例中我们无需这么做，所以签名本身是可逆的，能通过签名还原出DOM结构。
3. 父节点签名包含子节点签名，这样在我们比较两个父节点的时候能关注整个DOM结构。
4. 签名包含的各个属性顺序排列。

在DOM属性选择上，各位可以自行添加删减，本例中，我选取了DOM节点类型和`class`值作为属性，之所以如此，我是基于一个事实：现阶段大部分网站依靠DOM类型和`class`来制定样式，至于ID和内联样式不做考虑，因为两者对样式影响不大（而类似React inline style这样的解决方案，一来覆盖面太小，二来这个方案本意并不是解决样式问题，在这里不讨论）。基于如上规则，我们来举几个实例。

```html
<div>
  <div class="title">Title</div>
  <div class="content">
    <a href="#">Link</a>
    <p>This is the content.</p>
  </div>
</div>
```

为了展示方便，我首先将上述DOM转化为如下形式，去除闭合标签，采用缩进来表示：

```yml
div
  div.title
  div.content
    a
    p
```

我所做的处理就是将这些关键字标记，并按一定顺序连接：

```
[div][div][.title][div][.content][a][p]
```

细心的同学可能注意到了，我将父子关系给丢弃了，这个问题后面3.3中将会说明。

随后我将所有关键字映射到单个字符，本例中我采用`Unicode`，也可以采用其他方案，我制定了如下规则：

* **[\u0000 - \u0999]** 保留，用作特殊字符
* **[\u1000 - \u1999]** 做为映射DOM节点类型
* **[\u2000 - \u2999]** 做为映射各个`class`

上例中，我们可以获得这样一个映射表：

| 关键字 | 签名字符 |
| --- | --- |
| div | \u1000 |
| a | \u1001 |
| p | \u1002 |
| .title | \u2000 |
| .content | \u2001 |

故上述DOM结构可以表现为`\u1000\u1000\u2000\u1000\u2001\u1001\u1002`。

加入这时候有个及其相似的DOM如下：

```html
<div class="hide">
  <div class="title">Title</div>
  <div class="content">
    <a href="#">Link</a>
    <p>This is the content.</p>
  </div>
</div>
```

可以发现这儿的父节点多了一个`hide class`，我们只要将`.hide`增加入映射表中`\u2002`。可以获得这个DOM的签名为：`\u1000\u2002\u1000\u2000\u1000\u2001\u1001\u1002`。

由两个签名可知，第二个DOM相较于前一个在第一个`div`元素中多了一个`hide class`。这个变化占第二个DOM全部签名的`1/8 = 12.5%`。到此，我们可以说：

**在当前签名下，从第二个DOM转变为第一个DOM需要经过1个步骤，这个步骤改变了签名12.5%的内容。**

### 2.2 DOM签名相似性比较

以上述两个DOM为例，我们知道若要从DOM2转化为DOM1，需要经过1个步骤，这个步骤减去了一个`hide class`。而很明显，**对于任意的两个DOM，都可以经过有限的步骤从一个转化为另一个**。这些步骤都可以反映到这个DOM的签名中：

| DOM改变 | 签名改变 |
| --- | --- |
| 增加DOM节点 | 签名中相应某处增加对应的子DOM签名 |
| 删除DOM节点 | 签名中相应某处删除对应的子DOM签名 |
| 修改DOM节点类型 | 签名中修改对应DOM的类型签名字符 |
| 增加DOM class | 签名中相应某处增加对应的class签名字符 |
| 删除DOM class | 签名中相应某处删除对应的class签名字符 |

所以，**若想得知一个DOM经过多少个步骤可以转化成另一个DOM，那么只要知道其签名经过多少步修改即可得到另一个DOM的签名即可，反之也成立。**

那么问题就转化成了：如何得到一个签名转化成另一个签名的最小步骤数，进一步说就是，**如何得到两个字符串，由一个转化为另一个所需的最小步骤数。**

针对这个问题，有个解叫**编辑距离（edit distance）[[1]](https://github.com/sekaiamber/content-base-crawler/blob/master/doc/doc.md#5-参考)**，本例中，我使用编辑距离来作为支撑两个DOM相似性的依据。

对于编辑距离，更加详细的定义应该是：

> 在计算机科学中，编辑距离是一种通过计数两个字符串从一个转化成另一个的最小步骤数来量化彼此的不同的方法。    ---- 维基百科

编辑距离在很多领域运用广泛：DNA对比、拼写纠错、机器翻译、语意分析等领域。它计算简单，实现也不复杂，简直是算法菜鸡们的福音。

我们来举个编辑距离是实际例子[[1]](https://github.com/sekaiamber/content-base-crawler/blob/master/doc/doc.md#5-参考)，若想将`kitten`变为`sitting`，那么则需要下述步骤：

> 1. kitten → sitten (substitution of "s" for "k")
> 2. sitten → sittin (substitution of "i" for "e")
> 3. sittin → sitting (insertion of "g" at the end).

归纳下来可以说这里的改变总共只有3种情况：`替换`、`删除`、`插入`。而编辑距离的算法半个世纪前已经公布，并从数学上证明了可行，下面显示这个算法：

> 对于两个字符串`a = a1 ... an`和`b = b1 ... bm`，他们的编辑距离`dmn`算法如下：
> ![Edit_distance](https://wikimedia.org/api/rest_v1/media/math/render/svg/1deeeaebff36dc4bdc79778bcafe0ec17ce63f83)
> 其中，`Wdel`、`Wins`、`Wsub`分别表示`删除`、`插入`和`替换`目标字符串所花费的代价，在传统的`Levenshtein距离`中，每单个字符的每种操作代价均为1。

从数学公式上来看，很明显这是一个动态规划问题，若各个操作的代价均为1，用程序语言来描述的话，事实上就是这样：

1. 如果对于任意一个字符`b[0, k]`串转化为一个空字符，那么就删除所有字符即可，长度为k，花费`W_del(b[0, k]) = k`。
2. 如果对于一个空字符串转化为任意一个字符串`a[0, k]`，那么只要插入所有字符即可，长度为k，花费`W_ins(a[0, k]) = k`。
3. 如果对于`b[0, i]`转化为`a[0, j]`，那么则有两种情况：
    1. 若两个字符`b[i]`和`a[j]`相等，则`d(i, j)`等于`d(i - 1, j - 1)`，这很好理解，字符相等，就不需要改变，当前的改变数就继承了上个字符的改变数。
    2. 如果两个字符不相等，那么取下述3种情况的最小值：
        1. `d(i - 1, j) + 1`，相当于`b[i - 1]`转化到`a[j]`的步骤数加上一次删除`b[i]`字符的花费。
        2. `d(i, j - 1) + 1`，相当于`b[i]`转化到`a[j - 1]`的步骤数加上一次增加`a[j]`字符的花费。
        3. `d(i - 1, j - 1) + 1`，相当于`b[i - 1]`转化到`a[j - 1]`的步骤数加上一次替换`b[i]`为`a[j]`字符的花费。

Python程序如下[[2]](https://github.com/sekaiamber/content-base-crawler/blob/master/doc/doc.md#5-参考)：

```python
def editDistance(str1, str2, m , n):

    # If first string is empty, the only option is to
    # insert all characters of second string into first
    if m == 0:
        return n

    # If second string is empty, the only option is to
    # remove all characters of first string
    if n == 0:
        return m

    # If last characters of two strings are same, nothing
    # much to do. Ignore last characters and get count for
    # remaining strings.
    if str1[m - 1] == str2[n - 1]:
        return editDistance(str1, str2, m - 1, n - 1)

    # If last characters are not same, consider all three
    # operations on last character of first string, recursively
    # compute minimum cost for all three operations and take
    # minimum of three values.
    return 1 + min(
        editDistance(str1, str2, m, n - 1),    # Insert
        editDistance(str1, str2, m - 1, n),    # Remove
        editDistance(str1, str2, m - 1, n - 1)    # Replace
    )
```

可以通过存储中间计算量来破解递归，大大优化执行效率，优化后的代码可以看本例中[`/work/utils.py::editDistance`](https://github.com/sekaiamber/content-base-crawler/blob/master/work/utils.py#L13)这个函数。

至此，我们已经能正确比较出两个DOM签名的编辑距离，从而获得从一个DOM转化为另一个DOM需要的最小步骤。

## 3. 提取网页中的相似DOM

第2节中我们已经能正确判断出DOM的相似性了，本节中咱会针对一个网页来具体说明如何在无监督的情况下获得相似的DOM结构，并将它们分类。

### 3.1 平均距离

当我们一拿到HTML代码，通过程序会将一个节点（一般是`body`节点）作为父节点，并开始分析，基于第1节中的前提2，可得这儿的整个流程是针对某个DOM节点的子节点做互相比较。那么对于DOM中任意一个节点`Node_A`：

1. 将它的第一层子节点加入候选队列中。
2. 从候选队列中取出1个节点`Node_An`：
    1. 遍历`Node_A`中已有的相似DOM组。
    2. 计算每个组中每个DOM和`Node_An`的签名距离总和`sum([distances])`，并取平均获得`avg(sum([distances]))`。
    3. 若这个`avg(sum([distances])) / sign(Node_An).length`大于指定相似度，则认为`Node_An`属于这个组，将`Node_An`加入这个组。
    4. 否则，若`Node_An`不属于任何组，则新建一个相似组，里面只有一个`Node_An`成员。
    5. 将`Node_An`移出候选队列。
3. 重复第2步直到候选队列中没有任何节点。
4. 对于所有第一层子节点重复整个过程，并将获得的相似DOM组合并到`Node_A`的相似组中。

针对上述算法，只要将`Node_A`选定为`body`元素，即可获得整个网页的所有相似组，注意，其中也包含孤立的DOM结构，这种结构跟任何一组都没有相似性。

### 3.2 参数调整和优化

实际过程中，我们需要对3.1中的算法进行一系列调整，才能提高效率和回避许多不必要的计算。

根据第0节中的前提1，我们知道一般高价值的目标节点一般拥有许多第一层子元素，故在3.1的算法最开头增加一条判断：若子元素数量小于给定子元素最小值，则直接执行第4步。

根据第0节中的前提3，我们可以排除掉一些十分简单的第一层子元素进入判断流程，这个复杂度判断我一般选择使用DOM深度来进行判断。

在算法最后，可以去除一些数量稀少的相似组，比如我们认为同一个相似组中若数量少于给定数量，则认为这些都是噪音。

经过调整之后的算法如下：

1. 判断`Node_A`拥有多少子节点，若小于给定最小子节点数，则直接执行第8步。
2. 将`Node_A`的第一层子节点加入候选队列中。
3. 判断候选组中每个子节点的DOM深度，若小于给定的最小深度，则剔除出候选队列。
4. 重复第1步。
5. 从候选队列中取出1个节点`Node_An`：
    1. 遍历`Node_A`中已有的相似DOM组。
    2. 计算每个组中每个DOM和`Node_An`的签名距离总和`sum([distances])`，并取平均获得`avg(sum([distances]))`。
    3. 若这个`avg(sum([distances])) / sign(Node_An).length`大于指定相似度，则认为`Node_An`属于这个组，将`Node_An`加入这个组。
    4. 否则，若`Node_An`不属于任何组，则新建一个相似组，里面只有一个`Node_An`成员。
    5. 将`Node_An`移出候选队列。
6. 重复第5步直到候选队列中没有任何节点。
7. 遍历`Node_A`的相似组，将数量小于给定最小相似组节点数量的组剔除。
8. 对于所有第一层子节点重复整个过程，并将获得的相似DOM组合并到`Node_A`的相似组中。

故而本算法中将拥有4个参数来调整，他们分别是：`最小子节点数`、`子节点最小深度`、`最小相似度阈值`、`最小相似组节点数量`。这部分代码可以参考[`/work/webdom.py::WebDom.getSimilarBySignature`](https://github.com/sekaiamber/content-base-crawler/blob/master/work/webdom.py#L65)这部分代码。

### 3.3 一些特殊情况

在设计签名最初，咱就考虑到了一种情况，细心的同学可能已经发现，我们的这种签名设计抛弃了父子关系，在本例中这种情况不需要考虑，因为DOM操作跟字符串操作还是有所区别的。有如下几种情况。

情况1：增加或删除嵌套节点

DOM1：
```html
<div>
  <p></p>
</div>
```

DOM2：
```html
<div>
  <div>
    <p></p>
  </div>
</div>
```

对比上述两个签名，可以发现DOM2的签名跟DOM1的签名距离为1，从DOM操作来讲，就是往`p`元素外面套一层`div`，花费我们可以定为1，从签名上来讲就是增加了一个`div`签名字符，花费为1。

情况2： 相似DOM

DOM1：
```html
<div>
  <div></div>
  <p></p>
</div>
```

DOM2：
```html
<div>
  <div>
    <p></p>
  </div>
</div>
```

这种情况下DOM2和DOM1的签名完全一样，但是实际上这是两种不同的结构，在此，我们基于一个事实：现阶段大量网站使用`class`来定制样式，故上述这种情况在加入了`class`属性后实际上是大为不同的，并且参数中的`子节点最小深度`和第0节前提3也保证了，过于简单的DOM结构我们不会将它们计算入相似组中。甚至，我们可以将相对于父节点的深度信息加入到签名中来彻底解决这个问题。

### 3.4 优缺点

本方案对于网页结构改变有十分强大的抵抗性，只要页面表达的内容不变，不管DOM结构如何改变，相似性永远存在，本方案就是利用这种相似性来获取有价值内容。而且本案对于抵抗噪音也别有一套，很多网站在列表中会插入广告之类的非目标内容，大部分情况下，这些内容跟目标内容的DOM结构差异巨大，本方案能自动忽略这些噪音。

但是因为本方案是无监督的爬取，故一个页面上可能会产生多个相似内容，最终需要人工去辨别何种内容才是需要的东西。

天下没有万能药，大家可以很明显地发现，本方案适用于页面上有大量重复的内容的情况，并且重复内容是高价值的内容，若应对特种爬取，例如页面上特定几个区域的内容，这种方式就基本没啥用了。所以，多种爬虫方案配合起来，对症下药，才能真正覆盖大部分情况。

## 4. 实际测试

本例中`/example`目录中我写了若干个测试，大家都可以自行尝试。不过请首先自己访问一下目标页面，以防时间过久了网页已经不存在。

这里我们对B站进行测试，运行`/example/bilibili.py`：

```shell
$ python3 setup.py 'http://www.bilibili.com/video/bangumi-two-1.html' -d chrome -w examples/bilibili.py
```

页面内容如图：

![bilibili test](https://raw.githubusercontent.com/sekaiamber/content-base-crawler/master/doc/bilibili_test.png)

我需要抓取红框内的内容，故在程序中设定了红框里为root节点：

```python
body = driver.find_element_by_css_selector('.vd-list-cnt')
```

得到结果为：
```
Init finish 2017-01-11 20:23:39.588665
Dom ready 2017-01-11 20:23:39.615389
Webpage inited 2017-01-11 20:23:59.306820
UL.vd-list.l2
    Find dom pattern:

    ...

Show Doms: 2017-01-11 20:23:59.936743



UL.vd-list.l2 2017-01-11 20:23:59.936792
    Find dom pattern:
--------------------------------
【4月】双星之阴阳师 39
#39
5.2万
1240
TV-TOKYO
--------------------------------
【10月】怪物猎人物语ride on 13 【梦蓝字幕组】
重新上传第13话 本视频字幕由梦蓝字幕组制作，欢迎各位的收看。
90
2
口袋小ken
--------------------------------
【1月】漫研部～Surgical Friends～02【幻之】
ox星 封面灵魂作画......
4989
82
施主您菊花松了
--------------------------------
【1月/生肉】无畏战士 Bravest Warriors S03E01-02
Dingo | 封面 https://youtu.be/JDxPqmy-S4Y Bravest Warriors follows four teenaged heroes-for-hire as they warp through the universe to save adorable aliens and their worlds using the power of their emotions. Cartoon Hangover © Frederator Networks, Inc.
387
8
SerCom_KC
--------------------------------
【1月】黑白来看守所 15【独家正版】
#15
14.7万
4596
哔哩哔哩番剧
--------------------------------
【1月】兽娘动物园 01
#01
9.3万
2487
TV-TOKYO
--------------------------------
【1月/WEB】幼女战记(谭雅战记) 短篇 第01话【F宅】
直传 早见沙织的八嘎角色好久不见，悠木碧这次的大叔心萝莉身也配的不错，哈哈，就是TV那个人设太辣眼睛
6683
72
空灵雨迹
--------------------------------
【1月】Hand Shakers 01
#01
33.0万
8272
哔哩哔哩番剧
--------------------------------
【1月】ACCA13区监察课 01
#01
13.2万
6117
哔哩哔哩番剧
--------------------------------
【10月】忍者少女千鸟 / 信长的忍者 15
#15
5.2万
340
TV-TOKYO
--------------------------------
【4月】少年阿贝 GO!GO!小芝麻 27
#27
1107
56
哔哩哔哩番剧
--------------------------------
【1月/WEB】幼女战记 短篇 第1话
https://www.youtube.com/watch?v=_vqoDl9mkWM KADOKAWA频道每周更新
1.2万
86
雾中的银河
--------------------------------
【4月】Pripara 3rd 美妙天堂3 40
#40
8957
636
TV-TOKYO
--------------------------------
【10月】喵阿楞 15【独家正版】
#15
1.1万
504
哔哩哔哩番剧
--------------------------------
【1月】飙速宅男 第三季 01
#01
10.8万
2112
TV-TOKYO
--------------------------------
【1月】鬼平 01
#01
9.7万
1979
哔哩哔哩番剧
--------------------------------
【10月】TRICKSTER 13
#13
5.9万
1250
哔哩哔哩番剧
--------------------------------
【1月】新撰组镇魂歌 二分之一 01【独家正版】
#01
4.6万
404
哔哩哔哩番剧
--------------------------------
【1月】珈百璃的堕落 01
#01
38.3万
1.4万
哔哩哔哩番剧
--------------------------------
【2017/英语生肉】【大结局合集】终极蜘蛛侠：大战邪恶六人组 【英文字幕】
直传《终极蜘蛛侠第四季》终结篇：毕业日(°∀°)ﾉ
3792
266
DrStrider
```

可见我们正确获得各种信息，并且剔除了许多噪音和不需要的DOM结构

## 5. 参考

* [1]. [Wiki edit distance](https://en.wikipedia.org/wiki/Edit_distance)
* [2]. [Dynamic Programming - edit distance](http://www.geeksforgeeks.org/dynamic-programming-set-5-edit-distance/)
